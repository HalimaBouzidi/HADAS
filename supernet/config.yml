arch: 'attentive_nas_dynamic_model'

# Path to the pretrained supernet, e.g.,
supernet_checkpoint_path: "AttentiveNAS/attentive_nas_data/attentive_nas_cifar100.pth.tar"
resume: "AttentiveNAS/attentive_nas_data/attentive_nas_cifar100.pth.tar"

# Just in case you have more GPUs
n_gpu_per_node: 2
data_loader_workers_per_gpu: 4
num_nodes: 16
n_cpu_per_node: 32
gpu_type: 'GPU_Tesla_P100'
memory_per_node: '16g'

### Distributed settings ###
distributed: False ## We use model-parallelism instead of data-parallelism so we turn-off the data distribution setting
distributed_val: False
multiprocessing_distributed: True
dist_backend: 'nccl'
eval_only: True

### CIFAR100 dataset ###
dataset: 'cifar-100'
dataset_dir: "datasets/cifar-100"
n_classes: 100
drop_last: True

### Exit training parameters ###

batch_size_per_gpu: 64
augment: "auto_augment_tf"
warmup_epochs: 5
epochs: 30
start_epoch: 0

weight_decay_weight: 0.00001
weight_decay_bn_bias: 0.

loss: "kl-div" ## Loss function for exits training

optimizer:
    method: sgd
    momentum: 0.9
    nesterov: True

lr_scheduler:
    method: "warmup_linear_lr"
    base_lr: 0.01
    clamp_lr_percent: 0.0

# Sync-batchnormalization, suggested to use in BigNAS paper
sync_bn: False
bn_momentum: 0
bn_eps: 1e-5
augment: "auto_augment_tf"
post_bn_calibration_batch_num: 64
data_loader_workers_per_gpu: 4

print_freq: 200
seed: 0

# AttentiveNAS search space (supernet configurations)
# c: channels, d: layers, k: kernel size, t: expand ratio, s: stride, act: activation, se: se layer
supernet_config:
    use_v3_head: True
    resolutions: [192, 224, 256, 288]
    first_conv: 
        c: [16, 24]
        act_func: 'swish'
        s: 2
    mb1:
        c: [16, 24]
        d: [1, 2]
        k: [3, 5]
        t: [1]
        s: 1
        act_func: 'swish'
        se: False
    mb2:
        c: [24, 32]
        d: [3, 4, 5]
        k: [3, 5]
        t: [4, 5, 6]
        s: 2
        act_func: 'swish'
        se: False
    mb3:
        c: [32, 40] 
        d: [3, 4, 5, 6]
        k: [3, 5]
        t: [4, 5, 6]
        s: 2
        act_func: 'swish'
        se: True
    mb4:
        c: [64, 72] 
        d: [3, 4, 5, 6]
        k: [3, 5]
        t: [4, 5, 6]
        s: 2
        act_func: 'swish'
        se: False
    mb5:
        c: [112, 120, 128] 
        d: [3, 4, 5, 6, 7, 8]
        k: [3, 5]
        t: [4, 5, 6]
        s: 1
        act_func: 'swish'
        se: True
    mb6:
        c: [192, 200, 208, 216] 
        d: [3, 4, 5, 6, 7, 8]
        k: [3, 5]
        t: [6]
        s: 2
        act_func: 'swish'
        se: True
    mb7:
        c: [216, 224] 
        d: [1, 2]
        k: [3, 5]
        t: [6]
        s: 1
        act_func: 'swish'
        se: True
    last_conv:
        c: [1792, 1984]
        act_func: 'swish'